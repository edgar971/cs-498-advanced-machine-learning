{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    column_names = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "    data1 = np.array(pd.read_csv('./data/dataI.csv', names=column_names, skiprows=1))\n",
    "    data2 = np.array(pd.read_csv('./data/dataII.csv', names=column_names, skiprows=1))\n",
    "    data3 = np.array(pd.read_csv('./data/dataIII.csv', names=column_names, skiprows=1))\n",
    "    data4 = np.array(pd.read_csv('./data/dataIV.csv', names=column_names, skiprows=1))\n",
    "    data5 = np.array(pd.read_csv('./data/dataV.csv', names=column_names, skiprows=1))\n",
    "    data = np.array(pd.read_csv('./data/iris.csv', names=column_names, skiprows=1))\n",
    "    return [data, data1, data2, data3, data4, data5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPCA(data, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(data)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMeanSquareMean(dataA, dataB):\n",
    "    totals = []\n",
    "    number_of_features = 4\n",
    "    for i in range(len(dataA)):\n",
    "        for feature in range(number_of_features):\n",
    "            totals.append(np.square(dataA[i, feature] - dataB[i, feature]))\n",
    "    return np.array(totals).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSubmission(dataA, dataB, name):\n",
    "    headers = '0N, 1N, 2N, 3N, 4N, 0c, 1c, 2c, 3c, 4c'\n",
    "    results = np.concatenate((dataA, dataB), axis=1)\n",
    "    np.savetxt(f\"{name}-numbers.csv\", results, header=headers, delimiter=\",\", fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(noisy_datasets, noiseless, max_components, fit_on_noisy=False):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(noisy_datasets)):\n",
    "        errors = []\n",
    "        for n_components in range(max_components):\n",
    "            fit_data = noisy_datasets[i] if fit_on_noisy else noiseless\n",
    "            noiseless_pca = createPCA(fit_data, n_components)\n",
    "            transformed = noiseless_pca.transform(noisy_datasets[i])\n",
    "            inverted = noiseless_pca.inverse_transform(transformed)\n",
    "            errors.append(calculateMeanSquareMean(inverted, noiseless))\n",
    "        results.append(errors)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createReconstruction(data, n_components=2):\n",
    "    pca = createPCA(data, n_components)\n",
    "    transformed = pca.transform(data)\n",
    "    reconstructed = pca.inverse_transform(transformed)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseless_msn = train(datasets[1:], datasets[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_msn = train(datasets[1:], datasets[0], 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateSubmission(noisy_msn, noiseless_msn, \"edgarsp2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = createReconstruction(datasets[1])\n",
    "headers = 'Sepal.Length,Sepal.Width,Petal.Length,Petal.Width'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"edgarsp2-recon.csv\", reconstructed, header=headers, delimiter=\",\", fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
